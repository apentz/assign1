---
title: "Assignment 1"
output: html_notebook
---

# Description


# Approach


# Results


```{r, echo=TRUE}

# Load Required Packages
library(tidyverse)
library(coop)
library(NNLM)

# Load Data
load("C:/Users/nb174984/Desktop/Masters Data Science/Data Science for Industry/Assignment 1/book_ratings.Rdata")

# Data Exploration
glimpse(book_ratings)
glimpse(book_info)
glimpse(user_info)

items_n <- length(unique(book_ratings$ISBN))    #150
users_n <- length(unique(user_info$User.ID))  #10000

dim(book_ratings)
dim(user_info)

# Dealing with NA values
sum(is.na(book_ratings$Book.Rating))    #0
sum(is.na(user_info$Age))               #3311

# ages data is poor
table(book_ratings$Book.Rating)
table(user_info$Age)

# data for a new user
user_new <- data.frame(User.ID = rep(max(book_ratings$User.ID)+1,3), ISBN = c(0440234743, 0971880107, 0345417623), Book.Rating = c(2, 5, 3))

# small data for existing users
ratings_n <- book_ratings %>%
  filter(Book.Rating %in% c(1:10)) %>% 
  filter(User.ID %in% c("37712","240567","6575"))


# who are the 10 most similar users to user 60244?
head(sort(user_similarities["37712",], decreasing = TRUE),6)
# who are the 10 most dissimilar users to user 60244?
head(sort(user_similarities["37712",], decreasing = FALSE),6)

users_test <- book_ratings %>%
  filter(User.ID %in% c("37712","240567","6575")) %>% 
  select(User.ID,ISBN,Book.Rating)

# Task 1: reshape the data from long to wide format
read_books <- book_ratings %>% 
    filter(Book.Rating %in% c(1:10)) %>%              # remove not rated (value=0)
    spread(key = ISBN, value = Book.Rating, fill = 0) # pivot the data, ISBN are columns

# Task 1: function to reshape the data from long to wide format
cf_long_to_wide <- function(ratings_long){ 
  
# remove implicit ratings (not rated) and reshape the data from long to wide format
ratings_wide <- ratings_long %>% 
  filter(ratings_long[,3] %in% c(1:10)) %>%     # remove not rated (value=0)
  spread(key = colnames(ratings_long[2]), value = colnames(ratings_long[3]), fill = 0) # pivot the data, items become columns
  
# convert to matrix; convert first column to rownames 
users <- as.character(unlist(ratings_wide[,1]))
ratings_wide <- as.matrix(ratings_wide[,-1])
row.names(ratings_wide) <- users

return(ratings_wide)

}

# example all
ratings_wide_all <- cf_long_to_wide(book_ratings)
# example sample of existing
ratings_wide_test <- cf_long_to_wide(users_test)
# example new
ratings_wide_new <- cf_long_to_wide(user_new)

# Book.Title: the nanny diaries: a novel; Book.Author:emma mclaughlin has 2 ISBN numbers, sometimes with different ratings

users <- read_books$User.ID
items <- read_books$ISBN

View(read_books)

# Recommender System for Existing User and New User
# new_user <- data.frame(ISBN= c(0440234743, 0971880107, 0345417623), Book.Rating = c(2, 5, 3))

# Task 2: function to calculate cosine similarity for users and set diagonal to zero
cf_user_similarities <- function(ratings_wide){
  user_similarities <- coop::cosine(t(ratings_wide))
  diag(user_similarities) <- 0
  return(user_similarities)
}

# example all
user_similarities_all <- cf_user_similarities(ratings_wide_all)
user_similarities_all
# example existing
user_similarities_test <- cf_user_similarities(ratings_wide_test)
user_similarities_test
# example new
user_similarities_new <- cf_user_similarities(ratings_wide_new)
# who are the 10 most similar users to user 254?
head(sort(user_similarities_test["254",], decreasing = TRUE),2)
# who are the 10 most dissimilar users to user 254?
head(sort(user_similarities_test["254",], decreasing = FALSE),2)

# Task 3: function to recommend n items for any 1 user
cf_user_predict <- function (users, user_similarities, ratings_wide, predict_n) {
  
  # turn into character if not already
  user <- ifelse(is.character(users), users, as.character(users))
  
  # get scores
  user_scores <- data.frame(ISBN = colnames(ratings_wide), 
                            score = as.vector(user_similarities[users,] %*% ratings_wide), 
                            used = ratings_wide[users,])
  
  # sort 'unused' items by score and remove the 'used' column
  user_scores <- user_scores %>% 
    filter(used == 0, score != 0) %>% 
    arrange(desc(score)) %>% 
    select(-used)

  return(user_scores[1:predict_n,])
  
}

# example existing
cf_user_predict_test <- cf_user_predict(users = "37712", user_similarities = user_similarities_test, ratings_wide = ratings_wide_test, predict_n = 3)
cf_user_predict_test %>% left_join(book_info)
cf_user_predict_test <- cf_user_predict(users = "240567", user_similarities = user_similarities_test, ratings_wide = ratings_wide_test, predict_n = 3)
cf_user_predict_test %>% left_join(book_info)
# example new
cf_user_predict_new <- cf_user_predict(users = users_new, user_similarities = user_similarities_new, ratings_wide = ratings_wide_new)


# Task 4: function to recommend n items for more than 1 user
lapply(users, user_based_recommendations, user_similarities, viewed_movies)


## item-based collaborative filtering

# Task 1: function to reshape the data from long to wide format

# Task 2: function to calculate cosine similarity for items and set diagonal to zero
cf_item_similarities <- function(ratings_wide){
  item_similarities <- coop::cosine(ratings_wide)
  diag(item_similarities) <- 0
  return(item_similarities)
}

# example all
item_similarities_all <- cf_item_similarities(ratings_wide_all)
item_similarities_all
# example existing
item_similarities_test <- cf_item_similarities(ratings_wide_test)
item_similarities_test
# example new
item_similarities_new <- cf_item_similarities(ratings_wide_new)
# who are the 10 most similar users to item 0060392452?
head(sort(item_similarities_test["0060502258",], decreasing = TRUE),10)
# who are the 10 most dissimilar users to item 0060392452?
head(sort(item_similarities_test["0060502258",], decreasing = FALSE),10)

# Task 3: function to recommend n items for any 1 user
cf_item_predict <- function (users, item_similarities, ratings_wide, predict_n) {
  
  # turn into character if not already
  user <- ifelse(is.character(users), users, as.character(users))
  
  # get scores
  used <- row.names(item_similarities)[ratings_wide[user,] == TRUE]
  item_scores <- tibble(title = row.names(item_similarities), 
                        score = apply(item_similarities[,used], 1, sum),
                        used = ratings_wide[user,])

  # sort 'unused' items by score and remove the 'used' column
  user_scores <- user_scores %>% 
    filter(used == 0, score != 0) %>% 
    arrange(desc(score)) %>% 
    select(-used)

  return(user_scores[1:predict_n,])
  
}

# example existing
cf_item_predict_test <- cf_item_predict(users = "37712", item_similarities = item_similarities_test, ratings_wide = ratings_wide_test, predict_n = 3)
cf_item_predict_test %>% left_join(book_info)
cf_item_predict_test <- cf_item_predict(users = "240567", item_similarities = item_similarities_test, ratings_wide = ratings_wide_test, predict_n = 3)
cf_item_predict_test %>% left_join(book_info)
# example new
cf_item_predict_new <- cf_user_predict(users = users_new, item_similarities = item_similarities_new, ratings_wide = ratings_wide_new)


# Task 4: function to recommend n items for more than 1 user
lapply(users, user_based_recommendations, user_similarities, viewed_movies)


## matrix factorization
library(NNLM)
cf_mf <- function(ratings_wide, k_latent){
  
  set.seed(123)
  
  # build model without L2 and Bias
  model <- NNLM::nnmf(ratings_wide, method = 'scd', loss = 'mse', check.k = FALSE,
                        k = k_latent)
  # generate predictions
  predict <- model$W %*% model$H

  # return last mse (min) in the vector of iterations and take the sqrt to get RMSE
  rmse <- sqrt(model$mse[length(model$mse)])
  
  return(predict)
  return(rmse)
}
rmse_3 <- cf_mf(ratings_wide_all, 3)[2]
rmse_4 <- cf_mf(ratings_wide_all, 4)[2]

predict_3 <- cf_mf(ratings_wide_all, 3)[1]


ggplot(data = k_rmse,mapping = aes(y = rmse, x = k_latent)) + geom_point() + geom_line()


# assess the accuracy of the matrix factorization recommender system using cross-validation

library(NNLM)
set.seed(123)
cf_mf_cv <- function(ratings_long){
  
  # split into train and test sets
  set.seed(123)
  index <- sample(seq_len(nrow(ratings_long)), size = round(nrow(ratings_long)*0.8,0))
  train <- ratings_long[index,]  # train the model on 80% of the observed values
  test <- ratings_long[-index,]  # hold out 20% to assess prediction accuracy on the test set
  zero <- test                   # create a copy of the test ratings 
  zero[,3] <- NA                 # zero the test ratings
  train <- rbind(train,zero)     # combine zeros with the train set to preserve matrix size
  
  
  train_wide <- train %>% 
  filter(ratings_long[,3] %in% c(1:10)) %>%     # remove not rated (value=0)
  spread(key = colnames(ratings_long[2]), value = colnames(ratings_long[3]), fill = 0) # pivot the data, items become columns
  
  # convert to matrix; convert first column to rownames 
  users <- as.character(unlist(ratings_wide[,1]))
  ratings_wide <- as.matrix(ratings_wide[,-1])
  row.names(ratings_wide) <- users
  
  test_wide <- cf_long_to_wide(test)

  # model without L2 and Bias, repeated for k = 1 to 10 latent factors
  for (i in 1:10){
    # build model
    model <- NNLM::nnmf(train_wide, method = 'scd', loss = 'mse', check.k = FALSE, k=i)

    # generate predictions
    predict <- model$W %*% model$H
    
    # model accuracy is sum of squared errors
    errors_train <- (train_wide[index,] - predict[index,]) ^ 2 
    errors_test <- (test_wide - predict[-index,]) ^ 2
    
    # rmse
    rmse_train[i] <- sqrt(mean(errors_train[!is.na(train_wide)]))
    rmse_test[i] <- sqrt(mean(errors_test[!is.na(test_wide)]))
  }
  return(rmse_train)
  return(rmse_test)
}

k_rmse <- data.frame(k_latent = c(1:10),
                    rmse = cf_mf_cv(book_ratings))

ggplot(data = k_rmse,mapping = aes(y = rmse, x = k_latent)) + geom_point() + geom_line()


# use cross-validated performance of the recommender system above to assess the influence of adding L2 regularization and bias

# add a column of 1's and a row of 1's to the ratings matrix A



```



```{r}

## TESTING

# Load Required Packages
library(tidyverse)
library(coop)
library(NNLM)

# Load Data
load("C:/Users/nb174984/Desktop/Masters Data Science/Data Science for Industry/Assignment 1/book_ratings.Rdata")

# Task 1: reshape the data from long to wide format
ratings_wide_all <- cf_long_to_wide(book_ratings)
ratings_wide_all[1:12,1:12]

# Task 2: calculate cosine similarity for users and set diagonal to zero
user_similarities_all <- cf_user_similarities(ratings_wide_all)
user_similarities_all[1:12,1:12]

# Task 3: recommend n items for any 1 user
cf_user_predict_test <- cf_user_predict(users = "37712", user_similarities = user_similarities_test, ratings_wide = ratings_wide_test, predict_n = 3)
cf_user_predict_test %>% left_join(book_info)
cf_user_predict_test <- cf_user_predict(users = "240567", user_similarities = user_similarities_test, ratings_wide = ratings_wide_test, predict_n = 3)
cf_user_predict_test %>% left_join(book_info)

## item-based collaborative filtering
# Task 2: calculate cosine similarity for items and set diagonal to zero
item_similarities_all <- cf_item_similarities(ratings_wide_all)
item_similarities_all[1:7,1:7]

# Task 3: function to recommend n items for any 1 user
cf_item_predict_all <- cf_item_predict(users = "37712", item_similarities = item_similarities_all, ratings_wide = ratings_wide_all, predict_n = 3)
cf_item_predict_all %>% left_join(book_info)
cf_item_predict_all <- cf_item_predict(users = "240567", item_similarities = item_similarities_all, ratings_wide = ratings_wide_test, predict_n = 3)
cf_item_predict_all %>% left_join(book_info)

# Task 4: function to recommend n items for more than 1 user
lapply(users, user_based_recommendations, user_similarities, viewed_movies)


## matrix factorization
library(NNLM)
set.seed(123)
rmse <- cf_mf(ratings_wide_all)
plot(x=1:10, y=rmse, colour="steelblue")

# assess the accuracy of the matrix factorization recommender system using cross-validation


# use cross-validated performance of the recommender system above to assess the influence of adding L2 regularization and bias


```

